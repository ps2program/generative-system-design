{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(list(instruction_tuned_dataset))  # `list` required for streaming datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame back to a `datasets.Dataset`\n",
    "finetuning_dataset = Dataset.from_pandas(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push dataset to Hugging Face\n",
    "finetuning_dataset.push_to_hub(\"ps2program/ps-alpaca-dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some size checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to disk\n",
    "finetuning_dataset.save_to_disk(\"./\")\n",
    "\n",
    "# Check disk size (using Python's os module)\n",
    "import os\n",
    "\n",
    "def get_dir_size(path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "disk_size = get_dir_size(\"dataset_directory\")\n",
    "print(f\"Dataset disk size: {disk_size / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(finetuning_dataset,)\n",
    "# print(df)\n",
    "\n",
    "# Convert to pandas DataFrame for memory size calculation\n",
    "df = finetuning_dataset.to_pandas()\n",
    "memory_size = df.memory_usage(deep=True).sum()\n",
    "\n",
    "print(f\"Dataset memory size: {memory_size / (1024**2):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
